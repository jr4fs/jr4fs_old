<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="stylesheet" href="css/bootstrap.min.css">
		<link rel="stylesheet" type="text/css" href="css/style.css">
		<link href='http://fonts.googleapis.com/css?family=Lato:100,300,400' rel='stylesheet' type='text/css'>
		<link href='http://fonts.googleapis.com/css?family=Roboto:400,300,100' rel='stylesheet' type='text/css'>
		<link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400' rel='stylesheet' type='text/css'>

		<script type="text/javascript" src="js/bootstrap.min.js"></script>

		<title>Jaspreet's Homepage</title>
	</head>

	<div class="container blank-container">

		<header class="website-header">    
			<div class="d-flex flex-column flex-md-row align-items-center mb-3 border-bottom px-0 px-md-3 pt-4 pb-3">

	
		  <div class="website-header-box text-left d-block d-md-none my-2 pb-1">
			  <a href="/" class="plain">
			  <div class="vislang-head-text">
				  <img src="images/vislang-logo.png" class="group-logo-small" alt="Vision, Language and Learning Lab">
			  </div> 
			  <div class="institution-head-text">
				  <div class="divider-bar">|</div> <img src="images/uva_small.png" style="height:28px;margin-top:-4px">
			  </div>
			  </a>
		  </div>

		  <div class="website-header-box text-left mr-auto d-none d-md-block">
			<a href="/" class="plain">
			<div class="vislang-head-text">
				<img src="images/vislang-logo.png" class="group-logo" alt="Vision, Language and Learning Lab">
			  </div>
			  <div class="institution-head-text">
				  <div class="divider-bar" style="padding-right:16px;padding-left:16px">|</div> <img src="images/uva_full.png" style="height:48px;margin-top:-5px">
			</div>
			  </a>
		  </div>
			</div>
		</header>
	
</div>

	<div class="container mb-0">
		<div class="row">
	
			 <div class="px-1 px-md-4 py-3 col-lg-12">
	
				 <div class="subtext">
	
					  <img src="docs/prof.png" style="height:198px;" class="float-left mr-3 mb-3 img-thumbnail img-fluid" alt="Vicente Ordonez">
	
				<div class="x-badge mb-3" style="line-height: 1.2em;">
				<h3 id="name" class="p-0 m-0 mb-1">Jaspreet Ranjit</h3> 
				<div>
				  <div>M.S. in Computer Science <span style="color:#888"></span></div>
				  <div>School of Engineering and Applied Science</div>
				  <div><a href="http://www.cs.rice.edu">University of Virginia</a></div>
				  <div style="font-size:0.96em">jr4fs@virginia.edu</div>
				</div>
				</div>
				
				<div class="mt-5 mt-sm-3">
				  <p class="subtext">I am interested in the research topics of fairness and explainability of machine
					learning models. More broadly, I am interested in the fields of Natural Language Processing and Computer Vision and how the intersection of the two can produce multimodal architectures that help us understand our data better. I am particularly excited about research in the Vision and Language field surrounding biases in datasets and state of the art models. Currently, I am a Research Assistant in the <a href="https://www.vislang.ai/">Vision, Language and Learning Lab </a>, 
					working with <a href="https://www.vicenteordonez.com/">Prof. Vicente Ord&oacute;&ntilde;ez </a> on exploring gender biases in Visual Recognition Models. I have performed research in the <a href="https://engineering.virginia.edu/link-lab">Link Lab</a> under the mentorship of  <a href="https://www.madhurbehl.com/">Prof. Madhur Behl</a> on traffic scene understanding and safety of autonomous vehicles. In my recent internship at <a href="https://vimeo.com/">Vimeo</a>, I developed a framework to identify biases in search and recommendation models and prototyped <i>Learning to Rank</i> models for video based search. 
				  </p>
	
				  <p class="subtext m-0">Currently, I am a Master's student studying Computer Science at the <a href="https://engineering.virginia.edu/">University of Virginia</a> graduating in December 2021. I received my Bachelor of Science at the University of Virginia in Computer Science as a Rodman Scholar. 
					Working in three different labs throughout my time as a student at UVA has given me a unique and diversified skill set in Vision and Language Applications in Machine Learning. Throughout my time at UVA, I have worked diligently to developing both the analytical, and computational skills necessary to conduct meaningful research in this field and I am excited to continue honing my skills as a researcher in this field. 
					Here is a link to my <a href="docs/Resume.pdf"> curriculum vitae</a>.
				  </p>
				</div>
			  </div>
		</div>
	</div>

	<body>
		<div class="container">


			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Publications</h2>
				</div>
			
				<div class="blog-post subtext p-2">
					<ul class="list-unstyled">
			
					<li class="media">
						<img ALIGN="left" style="padding: 10px;" src="images/sdl.png" width="100" alt="">
						<div class="media-body">
						<p class="my-auto">
						<a class="blue_link" href="https://dl.acm.org/doi/abs/10.1145/3450267.3450544">
							Scenario2Vector: scenario description language based embeddings for traffic situations
						</a> 
						<span class="pub_authors d-lg-block">
							Aron Harder, <strong>Jaspreet Ranjit</strong>, Madhur Behl.
						</span>
						<span class="pub_info d-inline">
							International Conference on Cyber-Physical Systems. <strong>ICCPS 2021</strong>. May 2021.
						</span>
							[<a href="https://linklab-uva.github.io/sce2vector/">site</a>]
							[<a href="docs/sce2vec.bib">bibtex</a>] 
						</p>
						</div>
					</li>
			
					<li class="media">
						<img ALIGN="left" style="padding: 10px;" src="images/openset.png" width="100" alt="">
						<div class="media-body">
						<p class="my-auto">
						<a class="blue_link" href="https://dl.acm.org/doi/10.1145/3395352.3402901">
							Open set recognition through unsupervised and class-distance learning
						</a> 
						<span class="pub_authors d-lg-block">
							Andrew Draganov, Carter Brown, Enrico Mattei, Cass Dalton, <strong> Jaspreet Ranjit</strong>
						</span>
						<span class="pub_info d-inline">
							WISEC: Security and Privacy in Wireless and Mobile Networks. <strong>WiseML 2020</strong>. July 2020.
						</span>
							[<a href="https://dl.acm.org/doi/10.1145/3395352.3402901">acm</a>]
							[<a href="docs/exp.bib">bibtex</a>]  
						</p>
						</div>
					</li>
		
					</ul>
					
				</div><!-- /.blog-post -->
			</div> <!-- class="row" -->

			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Research Experience</h2>
				</div>
			
				<div class="blog-post subtext p-2">
					<ul class="list-unstyled">
			
					<li class="media">
						<img ALIGN="left" style="padding: 10px;" src="images/vislang.png" width="100" alt="">
						<div class="media-body">
						<p class="my-auto">
						<a>
							Analyzing Gender Biases in Visual Recognition Models
						</a> <br>
						<a class="blue_link" href="https://www.vislang.ai/">
							<b>The Vision, Language and Learning Lab </b>
						</a> 
						<span class="pub_authors d-lg-block">
							<strong>Jaspreet Ranjit</strong>, <a class="blue_link" href="http://vicenteordonez.com">Vicente Ord&oacute;&ntilde;ez</a></span>, <a class="blue_link" href="https://www.rayb.info/">Baishakhi Ray</a></span>
						</span> 
						<span class="pub_authors d-lg-block">
							Although visual recognition models have undergone many advancements in the past decade, they have been shown to reflect and amplify harmful societal biases often stemming from the large amount of data they have been trained on. I have been working on developing a tool that analyzes the implicit feature representations of large models with respect to bias. This tool allows for comparison of implicit feature representations across different models and synthesizes this data for convenient comparison.
						</span> 
						</p>
						</div>
					</li>

					<li class="media">
						<img ALIGN="left" style="padding: 10px;" src="images/sdl.png" width="100" alt="">
						<div class="media-body">
						<p class="my-auto">
						<a class="blue_link" href="https://dl.acm.org/doi/abs/10.1145/3450267.3450544">
							Scenario2Vector: Scenario Description Language Based Embeddings for Traffic Situations
						</a> <br>
						<a class="blue_link" href="https://engineering.virginia.edu/link-lab">
							<b>The Link Lab </b>
						</a> 
						<span class="pub_authors d-lg-block">
							<a class="blue_link" href="https://www.linkedin.com/in/aron-harder-a81052115/">Aron Harder</a>, <strong>Jaspreet Ranjit</strong>, <a class="blue_link" href="https://www.madhurbehl.com/index.html">Madhur Behl</a></span>
						</span> 
						<span class="pub_authors d-lg-block">
						In this paper we propose Scenario2Vector - a Scenario Description Language (SDL)
						based embedding for traffic situations that allows us to automatically search for similar traffic situations from large AV data-sets. We have also created a
						first of its kind, Traffic Scenario Similarity (TSS) dataset which contains human ranking annotations for the similarity between traffic
						scenarios. <a class="blue_link" href="https://dl.acm.org/doi/abs/10.1145/3450267.3450544">...</a>
						</span> 
						<span class="pub_info d-inline">
							International Conference on Cyber-Physical Systems. <strong>ICCPS 2021</strong>. May 2021.
						</span> 
						[<a href="https://linklab-uva.github.io/sce2vector/">site</a>]
						[<a href="docs/sce2vec.bib">bibtex</a>] 
						</p>
						</div>
					</li>

			
					<li class="media">
						<img ALIGN="left" style="padding: 10px;" src="images/uav.png" width="100" alt="">
						<div class="media-body">
						<p class="my-auto">
						<a>
							Object Detection for 3D Printed Unmanned Aerial Vehicle
						</a> <br>
						<span class="pub_authors d-lg-block">
							<span><strong>Jaspreet Ranjit</strong>, <a class="blue_link" href="https://www.linkedin.com/in/david-sheffler-3306a025/">David Sheffler</a></span>
						</span> <br>
						<span class="pub_authors d-lg-block">
							Developed a prototype of a 3D printed UAV that completes a mission autonomously and designed object detection algorithms on a raspberry pi interface.
						</span> 
						</p>
						</div>
					</li>

					<li class="media">
						<img class="mr-3 img-thumbnail" src="images/vislang.png" width="100" alt="">
						<div class="media-body">
						<p class="my-auto">
						<a class="blue_link" href="http://cs.virginia.edu/~lp2rv/websites/ChairSegments">
							Chair Segments: A Compact Benchmark for the Study of Object Segmentation
						</a> <br>
						<span class="pub_authors d-lg-block">
							Leticia Pinto-Alva, Ian K. Torres, Rosangel Garcia, Ziyan Yang, Vicente Ordonez
						</span>
						<span class="pub_info d-inline">
							arxiv:2011.14027 Nov 2020.
						</span>
							[<a href="http://cs.virginia.edu/~lp2rv/websites/ChairSegments">project page</a>]
							[<a href="https://github.com/uvavision/chair-segments">code</a>]
							[<a href="https://arxiv.org/abs/2012.01250">arxiv</a>]
							[<a href="files/chairsegments_arxiv_bib.txt">bibtex</a>]
						</p>
						</div>
					</li>


					</ul>
					
				</div><!-- /.blog-post -->
			</div> <!-- class="row" -->


			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Work Experience</h2>
				</div>
			</div> <!-- class="row" -->

			<div class="row row-thin gray">

				<div class="col-md-3">
					<img class="img-responsive img-embeded" src="images/vimeo.jpg">
				</div>
				<div class="col-md-9 text-thin" >
					<h4><a class="blue_link" href="placeholder">Vimeo</a></h4>
					<h5>Machine Learning Researcher</h5>
					<p style="font-size:90%;">Analyzed gender biases in Vimeo's search and recommendation system and formulated a pipeline with metrics that quantified gender biases in search results. Developed proof of concept learning to rank models, and an internal dataset for training/evaluating machine learning based search. Under the mentorship of <a href="https://www.linkedin.com/in/silvena-chan/">Silvena Chan</a>. 
					<a href="placeholder">...</a>
					</p>
					<h5>[ <a href="placeholder">paper</a> ]</h5>
				</div>
			</div>

			<div class="row row-thin gray">

				<div class="col-md-3">
					<img class="img-responsive img-embeded" src="images/mist.png">
				</div>
				<div class="col-md-9 text-thin" >
					<h4><a class="blue_link" href="https://www.minspinaltech.com/">Minimally Invasive Spinal Technology</a></h4>
					<h5>Lead Machine Learning Engineer and Software Development Engineer</h5>
					<p style="font-size:90%;">Developed machine learning algorithms for the analysis and prediction of scoliosis using Unet++ and Centernet architectures. Served as an agile scrum master, and organized weekly retrospective sessions. Advised by <a href="https://www.linkedin.com/in/alexander-a-singh/">Alexander Singh</a>. 
					<a href="docs/mist.pdf">...</a>
					</p>
					<h5>[ <a href="docs/mist.pdf">Letter of Recommendation</a> ]</h5>
				</div>
			</div>

			<div class="row row-thin gray">

				<div class="col-md-3">
					<img class="img-responsive img-embeded" src="images/exp.png">
				</div>
				<div class="col-md-9 text-thin" >
					<h4><a class="blue_link" href="https://www.exptechinc.com/">Expedition Technology</a></h4>
					<h5>Machine Learning Researcher</h5>
					<h5>Wise ML, 2021.</h5>
					<p style="font-size:90%;">Developed a novel semi-supervised framework for training classifiers and simultaneously
						detecting out-of-distribution inputs. Implemented the OpenMax algorithm: a methodology to adapt deep networks for open set recognition, which
						estimates the probability of an input being from an unknown class. Advised by Andrew Draganov.
					<a href="https://wisec2020.ins.jku.at/proceedings-wiseml/wiseml20-8.pdf">...</a>
					</p>
					<h5>[ <a href="https://wisec2020.ins.jku.at/proceedings-wiseml/wiseml20-8.pdf">paper</a> ]&nbsp&nbsp&nbsp&nbsp[ <a href="docs/exp.bib">bibtex</a> ]</h5>
				</div>
			</div>


			<div class="row row-thin gray">

				<div class="col-md-3">
					<img class="img-responsive img-embeded" src="images/exp.png">
				</div>
				<div class="col-md-9 text-thin" >
					<h4><a class="blue_link" href="https://www.exptechinc.com/">Expedition Technology</a></h4>
					<h5>Machine Learning Engineer</h5>
					<p style="font-size:90%;">Designed a custom convolutional neural network (CNN) working in the ML pipeline on the basis of existing
						VoxelNet and CenterNet architectures. Developed and optimized an end to end differentiable CNN by extending
						an existing codebase to modify preprocessing of data, inner CNN architecture, and post-processing and evaluation. Researched and leveraged anchorless object detection techniques for 3D point cloud object detection. Under the mentorship of Cheryl Danner. 
					<a href="https://tinyurl.com/exptech">...</a>
					</p>
					<h5>[ <a href="https://tinyurl.com/exptech">Research Overview</a> ]</h5>
				</div>
			</div>

			<div class="row row-thin gray">

				<div class="col-md-3">
					<img class="img-responsive img-embeded" src="images/nasa.png">
				</div>
				<div class="col-md-9 text-thin" >
					<h4><a class="blue_link" href="https://www.nasa.gov/">NASA Goddard Spaceflight Center</a></h4>
					<h5>Flight Software Developer</h5>
					<p style="font-size:90%;">Developed and benchmarked
						core Flight Software apps that directed AI image processing and command/telemetry with ground station. Under the mentorship of Alessandro Geist. 
					<a href="docs/nasagoddard.pdf">...</a>
					</p>
					<h5>[ <a href="docs/nasagoddard.pdf">Research Overview</a> ]</h5>
				</div>
			</div>

			<div class="row row-thin gray">

				<div class="col-md-3">
					<img class="img-responsive img-embeded" src="images/nasa.png">
				</div>
				<div class="col-md-9 text-thin" >
					<h4><a class="blue_link" href="https://www.nasa.gov/">NASA Langley Research Center</a></h4>
					<h5>3D Printing Engineer</h5>
					<p style="font-size:90%;">Worked with the characterization of 3D printer and acquired mechanical skills in the workings of a 3D printer. Used sensor technology to design to improve the dimensional integrity of a printed component. Analyzed trends in data collected from an IR temperature sensor, laser profilometer, IR camera, and load monitor. Under the mentorship of Dr. Godfrey Sauti. 
					<a href="docs/nasalangley.pdf">...</a>
					</p>
					<h5>[ <a href="docs/nasalangley.pdf">Research Overview</a> ]</h5>
				</div>
			</div>

		</div> <!-- class="container" -->
	</body>
</html>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-70676570-2', 'auto');
	ga('send', 'pageview');
</script>











  
	  
  
